{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net Model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "#masks = np.expand_dims(masks, axis=-1)  # Expand dims to have a single channel\n",
    "\n",
    "\n",
    "def weighted_binary_crossentropy(y_true, y_pred, weight=1.0):\n",
    "    \"\"\"\n",
    "    Weighted binary crossentropy between an output tensor and a target tensor.\n",
    "    \n",
    "    Parameters:\n",
    "    - y_true: True labels. Tensor of the same shape as `y_pred`.\n",
    "    - y_pred: Predicted labels. Tensor of the same shape as `y_true`.\n",
    "    - weight: Weight for the positive class (scalar).\n",
    "    \n",
    "    Returns:\n",
    "    - Weighted binary crossentropy loss.\n",
    "    \"\"\"\n",
    "    # Ensure tensors are of floating point type for arithmetic operations\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    \n",
    "    # Calculate the binary crossentropy\n",
    "    bce = binary_crossentropy(y_true, y_pred)\n",
    "    \n",
    "    # Weights for each class based on y_true\n",
    "    # Adjust for the fact that y_true may have an extra dimension\n",
    "    weights = tf.where(tf.equal(y_true, 1), weight, 1.0)\n",
    "    \n",
    "    # Weighted loss\n",
    "    weighted_bce = weights * bce\n",
    "    \n",
    "    # Return the mean of the weighted BCE loss\n",
    "    return tf.reduce_mean(weighted_bce)\n",
    "\n",
    "\n",
    "def unet(input_size=(128, 128, 3)):\n",
    "    inputs = Input(input_size)\n",
    "    # layers\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    up1 = Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(conv2)\n",
    "    merge1 = concatenate([conv1, up1], axis=3)\n",
    "    convUp1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge1)\n",
    "    convUp1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(convUp1)\n",
    "    \n",
    "    # output layer\n",
    "    convFinal = Conv2D(1, 1, activation='sigmoid')(convUp1)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[convFinal])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Assuming 'images' and 'masks' are predefined datasets for training\n",
    "# Example of model compilation with custom loss\n",
    "model = unet()\n",
    "model.compile(optimizer='adam', \n",
    "              loss=lambda y_true, y_pred: weighted_binary_crossentropy(y_true, y_pred, weight=10.0), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Replace 'images' and 'masks' with your actual training data variables\n",
    "model.fit(images, masks, batch_size=32, epochs=10, validation_split=0.1)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
